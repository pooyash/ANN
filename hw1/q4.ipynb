{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "private_outputs": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ADZvUiO7brMo"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import copy\n",
        "import scipy as sp\n",
        "sns.set_theme()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New section"
      ],
      "metadata": {
        "id": "iSOcpTcUkFzf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ## connecting to the google drive\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "# gpath = r'/content/drive/MyDrive/'\n",
        "# df = pd.read_csv(gpath)\n",
        "#!pip uninstall tensorflow\n",
        "!pip install tensorflow\n"
      ],
      "metadata": {
        "id": "qeoyrLgEepvz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!gdown --id '1rJ6b2nPGtvrkTz_0KCcAnmL8uECAr6Cy' --output CarPrice_Assignment.csv\n",
        "df = pd.read_csv('CarPrice_Assignment.csv')"
      ],
      "metadata": {
        "id": "ppomHRfpcaV0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "vat-f-Sbd8On"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.isna().sum()"
      ],
      "metadata": {
        "id": "PJRgz3CYd8S0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1 = copy.deepcopy(df)\n",
        "df1['CompanyName'] = df1.CarName.str.split(\" \").str[0]\n",
        "df1.drop(['CarName', 'car_ID', 'symboling'], axis=1, inplace=True)\n",
        "df1"
      ],
      "metadata": {
        "id": "Q6vkOQQLd8VW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1['CompanyName'].unique()"
      ],
      "metadata": {
        "id": "ugcYwyZTg9G2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df2 = copy.deepcopy(df1)\n",
        "df2.loc[df2['CompanyName'] == 'maxda', 'CompanyName'] = 'mazda'\n",
        "df2.loc[df2['CompanyName'] == 'Nissan', 'CompanyName'] = 'nissan'\n",
        "df2.loc[df2['CompanyName'] == 'porcshce', 'CompanyName'] = 'porsche'\n",
        "df2.loc[df2['CompanyName'] == 'toyouta', 'CompanyName'] = 'toyota'\n",
        "df2.loc[df2['CompanyName'] == 'vokswagen', 'CompanyName'] = 'volkswagen'\n",
        "df2.loc[df2['CompanyName'] == 'vw', 'CompanyName'] = 'volkswagen'\n",
        "\n",
        "df2['CompanyName'].unique()"
      ],
      "metadata": {
        "id": "bXyIYFnhg9LS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df2.dtypes"
      ],
      "metadata": {
        "id": "rWarSeQawds5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df3 = copy.deepcopy(df2)\n",
        "\n",
        "# get the dummies and store it in a variable\n",
        "dummies = pd.get_dummies(data=df2, columns=['fueltype', 'aspiration', 'doornumber', 'carbody', 'drivewheel', 'enginelocation', 'enginetype', 'cylindernumber', 'fuelsystem', 'CompanyName'])\n",
        " \n",
        "# Concatenate the dummies to original dataframe\n",
        "df4 = pd.concat([df3, dummies], axis='columns')\n",
        " \n",
        "# drop the values\n",
        "df4.drop(['fueltype', 'aspiration', 'doornumber', 'carbody', 'drivewheel', 'enginelocation', 'enginetype', 'cylindernumber', 'fuelsystem', 'CompanyName'], axis='columns', inplace=True)\n",
        "df4[['curbweight', 'enginesize', 'horsepower', 'peakrpm', 'citympg', 'highwaympg']] = df4[['curbweight', 'enginesize', 'horsepower', 'peakrpm', 'citympg', 'highwaympg']].astype(float)\n",
        "df4"
      ],
      "metadata": {
        "id": "xPNs8bRFg9M_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "class MultiColumnLabelEncoder:\n",
        "    def __init__(self,columns = None):\n",
        "        self.columns = columns # array of column names to encode\n",
        "\n",
        "    def fit(self,X,y=None):\n",
        "        return self # not relevant here\n",
        "\n",
        "    def transform(self,X):\n",
        "        '''\n",
        "        Transforms columns of X specified in self.columns using\n",
        "        LabelEncoder(). If no columns specified, transforms all\n",
        "        columns in X.\n",
        "        '''\n",
        "        output = X.copy()\n",
        "        if self.columns is not None:\n",
        "            for col in self.columns:\n",
        "                output[col] = LabelEncoder().fit_transform(output[col])\n",
        "        else:\n",
        "            for colname,col in output.iteritems():\n",
        "                output[colname] = LabelEncoder().fit_transform(col)\n",
        "        return output\n",
        "\n",
        "    def fit_transform(self,X,y=None):\n",
        "        return self.fit(X,y).transform(X)\n",
        "\n",
        "\n",
        "\n",
        "df5 = MultiColumnLabelEncoder(columns = ['fueltype', 'aspiration', 'doornumber', 'carbody', 'drivewheel', 'enginelocation', 'enginetype', 'cylindernumber', 'fuelsystem', 'CompanyName']).fit_transform(df3)\n",
        "df5\n"
      ],
      "metadata": {
        "id": "vQDVUhj6MJ00"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corr = df5.corr()\n",
        "corr.style.background_gradient(cmap='coolwarm')"
      ],
      "metadata": {
        "id": "z69ZCaiMMJ5h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.histplot(data=df5, x='price')\n",
        "plt.title('Distribution of Prices')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "-a2NafKWZ-E6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.scatterplot(data=df5, x='enginesize', y='price')\n",
        "plt.title('Scatter plot of price based on engine size')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "0Sxd8TbbarV-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X = df5.drop('price', axis=1)\n",
        "y = df5['price']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=2023)\n"
      ],
      "metadata": {
        "id": "_5gAKwR0MJ7U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "\n",
        "# Fit\n",
        "scaler.fit(X_train)\n",
        "\n",
        "# Apply the transformation\n",
        "X_train = scaler.transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# X_train = X_train.toarray()\n",
        "# X_test = X_test.toarray()"
      ],
      "metadata": {
        "id": "-Y_Kyh_EMKAD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New section"
      ],
      "metadata": {
        "id": "-Sv_hwoaAu7h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import Adam, RMSprop\n",
        "from tensorflow.keras import backend as K\n",
        "from sklearn.metrics import r2_score\n",
        "\n"
      ],
      "metadata": {
        "id": "PFJL7CKWMKB9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def rmse(y_true, y_pred):\n",
        "    return K.sqrt(K.mean(K.square(y_pred - y_true)))\n",
        "\n",
        "def mse(y_true, y_pred):\n",
        "    squared_difference = tf.square(y_true - y_pred)\n",
        "    return tf.reduce_mean(squared_difference, axis=-1)  # Note the `axis=-1`\n",
        "\n",
        "\n",
        "#model = Sequential([ Dense(256, activation='relu'), Dense(256, activation='relu'), Dense(128, activation='relu'), Dense(1)])\n",
        "\n",
        "model = Sequential([Dense(256, activation='relu'), Dense(256, activation='relu'), Dense(1)])\n",
        "#model = Sequential([ Dense(256, activation='relu'), Dense(1) ])\n",
        "\n",
        "model.compile(\n",
        "    loss=mse,              ### or mse\n",
        "    optimizer=Adam(),    ### or adam\n",
        "    metrics=[rmse]\n",
        ")\n",
        "\n",
        "history = model.fit(X_train, y_train, validation_split=0.25, epochs=5000)"
      ],
      "metadata": {
        "id": "SRApiLxFg9Si"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train set Accuracy and Validation set Accuracy\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('َAdam Optimizer - Relu Activation Function')\n",
        "plt.ylabel('RMSE')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='best')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "wwcMZz7HYfv7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = model.predict(X_test)\n",
        "r2_score(y_test, predictions)"
      ],
      "metadata": {
        "id": "jSCfJCLZYfxa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = model.predict(X_test)\n",
        "predictions[:5]"
      ],
      "metadata": {
        "id": "G1cT2s-BYf27"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_test[:5]"
      ],
      "metadata": {
        "id": "iZGbHr4FX8pN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "mean_squared_error(y_test[:5],predictions[:5])"
      ],
      "metadata": {
        "id": "kI9M_z2ZZAhn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}